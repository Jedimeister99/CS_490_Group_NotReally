{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch CNN to Test on the Generated Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/max/3288/1*uAeANQIOQPqWZnnuH-VEyw.jpeg'   width=\"700\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "os.chdir('c:/users/nicolas/documents/data/faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading all file names for the TRAIN set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('combined/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = [i for i in files if (i[-34] in ('0', '1')) and len(i[-37:-35].strip('\\\\').strip('d'))  == 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i[-34] for i in files if (i[-34] in ('0', '1')) and len(i[-37:-35].strip('\\\\').strip('d')) > 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = ['men', 'women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y) == len(faces), 'The X and Y are not of the same length!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting shape info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow, ncol, nchan = 60, 60, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the shape width/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    if img.shape[0]<img.shape[1]:\n",
    "        x = img.shape[0]\n",
    "        y = img.shape[1]\n",
    "        crop_img = img[: , int(y/2-x/2):int(y/2+x/2)]\n",
    "    else:\n",
    "        x = img.shape[1]\n",
    "        y = img.shape[0]\n",
    "        crop_img = img[int(y/2-x/2):int(y/2+x/2) , :]\n",
    "\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading and cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 15 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Scaling...', end='')\n",
    "start = time()\n",
    "x = []\n",
    "num_to_load = len(faces)\n",
    "for ix, file in enumerate(faces[:num_to_load]): \n",
    "    image = plt.imread(file, 'jpg')\n",
    "    image = Image.fromarray(image).resize((dim, dim)).convert('L')\n",
    "    image = crop(np.array(image))\n",
    "    x.append(image)\n",
    "print(f'\\rDone. {int(time() - start)} seconds')\n",
    "y = y[:num_to_load]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turning the pictures into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(x, dtype=np.float32)\n",
    "ytrain = np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20638, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "assert xtrain.shape[1] == dim\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y shapes are correct! (20638 samples each)\n"
     ]
    }
   ],
   "source": [
    "if xtrain.shape[0] == ytrain.shape[0]:\n",
    "    print('X and Y shapes are correct! (%i samples each)' % xtrain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xtrain.ndim == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data we are using is 20,638 pictures.\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of the data we are using is {xtrain.shape[0]:,} pictures.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files, faces = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation, splitting input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = np.random.choice(np.where(ytrain == 0)[0], 8_000)\n",
    "m_array = xtrain[men]\n",
    "m_target = ytrain[men]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "women = np.random.choice(np.where(ytrain == 1)[0], 8_000)\n",
    "w_array = xtrain[women]\n",
    "w_target = ytrain[women]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack([m_array, w_array])\n",
    "y_train = np.concatenate([m_target, w_target], axis=0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 60, 60), (16000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "permut = np.random.permutation(np.arange(x_train.shape[0]))\n",
    "x_train = x_train[permut]\n",
    "y_train = y_train[permut]\n",
    "assert y_train.sum() == 8_000, 'The classes aren\\'t balanced.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X is 16,000 and the size of Y is 16,000.\n"
     ]
    }
   ],
   "source": [
    "x_size, y_size = x_train.shape[0], y_train.shape[0]\n",
    "print(f'The size of X is {x_size:,} and the '\\\n",
    "     f'size of Y is {y_size:,}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the test set for MEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'generated_men_aae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob(directory + '/split' + '/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_files) == 25_000, 'There is not 25,000 files, '\\\n",
    "    'but %i.' % len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 4 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Scaling...', end='')\n",
    "start = time()\n",
    "x = []\n",
    "num_to_load = 10_000\n",
    "for ix, file in enumerate(test_files[:num_to_load]): \n",
    "    image = plt.imread(file, 'jpg')\n",
    "    image = Image.fromarray(image).resize((dim, dim)).convert('L')\n",
    "    image = np.array(image)\n",
    "    x.append(image)\n",
    "print(f'\\rDone. {int(time() - start)} seconds')\n",
    "y_gen_men = np.repeat(0, num_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(x).shape == (num_to_load, 60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Done. 0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "xtest_men = np.array(x, dtype=np.float32)\n",
    "ytest_men = np.array(y_gen_men, dtype=np.int32)\n",
    "print(f'\\rDone. {int(time() - start)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the test set for WOMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'generated_women_aae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob(directory + '/split' + '/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_files) == 25_000, 'There is not 25,000 files, '\\\n",
    "    'but %i.' % len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 5 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Scaling...', end='')\n",
    "start = time()\n",
    "x = []\n",
    "num_to_load = 10_000\n",
    "for ix, file in enumerate(test_files[:num_to_load]): \n",
    "    image = plt.imread(file, 'jpg')\n",
    "    image = Image.fromarray(image).resize((dim, dim)).convert('L')\n",
    "    image = np.array(image)\n",
    "    x.append(image)\n",
    "print(f'\\rDone. {int(time() - start)} seconds')\n",
    "y_gen_women = np.repeat(1, num_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_women = np.array(x, dtype=np.float32)\n",
    "ytest_women = np.array(y_gen_women, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(x).shape == (num_to_load, 60, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.vstack([xtest_men, xtest_women])\n",
    "y_test = np.concatenate([ytest_men, ytest_women], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 60, 60), (16000,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "permut = np.random.permutation(np.arange(x_test.shape[0]))\n",
    "x_test = x_test[permut]\n",
    "y_test = y_test[permut]\n",
    "assert y_test.sum() == y_test.shape[0]/2, 'The classes aren\\'t balanced.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X is 20,000 and the size of Y is 20,000.\n"
     ]
    }
   ],
   "source": [
    "x_size, y_size = x_test.shape[0], y_test.shape[0]\n",
    "print(f'The size of X is {x_size:,} and the '\\\n",
    "     f'size of Y is {y_size:,}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_test.shape[0] == x_test.shape[0] == y_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.eye(2)[y_train]\n",
    "# y_test = np.eye(2)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling, casting the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.     \n"
     ]
    }
   ],
   "source": [
    "print('Scaling...', end='') \n",
    "x_train = x_train.reshape(-1, 1, dim, dim).astype('float32') / 255 \n",
    "x_test = x_test.reshape(-1, 1, dim, dim).astype('float32') / 255\n",
    "y_train = y_train.astype('int64')\n",
    "y_test = y_test.astype('int64')\n",
    "print('\\rDone.     ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dimension: 20000 \n",
      "Second dimension: 1 \n",
      "Third dimension: 60 \n",
      "Fourth dimension: 60\n"
     ]
    }
   ],
   "source": [
    "samples, first, second, third = x_test.shape\n",
    "print('First dimension: %i' % samples,\n",
    "     '\\nSecond dimension: %i' % first,\n",
    "     '\\nThird dimension: %i' % second,\n",
    "     '\\nFourth dimension: %i' % third)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sending the arrays to Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors successfully flushed to CUDA.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x_train = torch.from_numpy(x_train) \n",
    "    x_test = torch.from_numpy(x_test) \n",
    "    y_train = torch.from_numpy(y_train) \n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    print('Tensors successfully flushed to CUDA.')\n",
    "else:\n",
    "    print('CUDA not available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clearning memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially image size, W = 60 <br>\n",
    "Kernel Size, k = 3 <br>\n",
    "Stride , s = 1 <br>\n",
    "Padding, P = 0 <br>\n",
    "The formula for the number of outputs to the next layer of conv2d is: O = { (W - k + 2*P)/s } + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        a = 32 #* 4\n",
    "        b = 64 #* 4\n",
    "        c = 128 #* 4\n",
    "        self.conv1 = nn.Conv2d(1, a, 3)\n",
    "        self.conv2 = nn.Conv2d(a, b, 3)\n",
    "        self.conv3 = nn.Conv2d(b, c, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(5*5*c, 1024) \n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        \n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTrain:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.len = x_train.shape[0]\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return x_train[index], y_train[index]#.unsqueeze(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTest:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.len = x_test.shape[0]\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return x_test[index], y_test[index]#.unsqueeze(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making instances of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FaceTrain()\n",
    "test = FaceTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1/30]  [Training Loss: 0.194]  [Test Loss: 0.043]  [Test Accuracy: 0.997]\n",
      "[Epoch: 2/30]  [Training Loss: 0.175]  [Test Loss: 0.016]  [Test Accuracy: 0.999]\n",
      "[Epoch: 3/30]  [Training Loss: 0.152]  [Test Loss: 0.017]  [Test Accuracy: 0.999]\n",
      "[Epoch: 4/30]  [Training Loss: 0.132]  [Test Loss: 0.013]  [Test Accuracy: 1.000]\n",
      "[Epoch: 5/30]  [Training Loss: 0.120]  [Test Loss: 0.023]  [Test Accuracy: 1.000]\n",
      "[Epoch: 6/30]  [Training Loss: 0.102]  [Test Loss: 0.028]  [Test Accuracy: 0.999]\n",
      "[Epoch: 7/30]  [Training Loss: 0.099]  [Test Loss: 0.010]  [Test Accuracy: 1.000]\n",
      "[Epoch: 8/30]  [Training Loss: 0.084]  [Test Loss: 0.012]  [Test Accuracy: 0.999]\n",
      "[Epoch: 9/30]  [Training Loss: 0.067]  [Test Loss: 0.010]  [Test Accuracy: 1.000]\n",
      "[Epoch: 10/30]  [Training Loss: 0.061]  [Test Loss: 0.008]  [Test Accuracy: 1.000]\n",
      "[Epoch: 11/30]  [Training Loss: 0.054]  [Test Loss: 0.012]  [Test Accuracy: 0.997]\n",
      "[Epoch: 12/30]  [Training Loss: 0.050]  [Test Loss: 0.003]  [Test Accuracy: 1.000]\n",
      "[Epoch: 13/30]  [Training Loss: 0.041]  [Test Loss: 0.007]  [Test Accuracy: 1.000]\n",
      "[Epoch: 14/30]  [Training Loss: 0.038]  [Test Loss: 0.006]  [Test Accuracy: 1.000]\n",
      "[Epoch: 15/30]  [Training Loss: 0.031]  [Test Loss: 0.006]  [Test Accuracy: 1.000]\n",
      "[Epoch: 16/30]  [Training Loss: 0.031]  [Test Loss: 0.007]  [Test Accuracy: 0.997]\n",
      "[Epoch: 17/30]  [Training Loss: 0.023]  [Test Loss: 0.004]  [Test Accuracy: 0.999]\n",
      "[Epoch: 18/30]  [Training Loss: 0.032]  [Test Loss: 0.014]  [Test Accuracy: 0.995]\n",
      "[Epoch: 19/30]  [Training Loss: 0.021]  [Test Loss: 0.001]  [Test Accuracy: 1.000]\n",
      "[Epoch: 20/30]  [Training Loss: 0.022]  [Test Loss: 0.003]  [Test Accuracy: 0.999]\n",
      "[Epoch: 21/30]  [Training Loss: 0.021]  [Test Loss: 0.008]  [Test Accuracy: 0.998]\n",
      "[Epoch: 22/30]  [Training Loss: 0.027]  [Test Loss: 0.009]  [Test Accuracy: 0.998]\n",
      "[Epoch: 23/30]  [Training Loss: 0.020]  [Test Loss: 0.029]  [Test Accuracy: 0.991]\n",
      "[Epoch: 24/30]  [Training Loss: 0.012]  [Test Loss: 0.006]  [Test Accuracy: 0.998]\n",
      "[Epoch: 25/30]  [Training Loss: 0.021]  [Test Loss: 0.019]  [Test Accuracy: 0.996]\n",
      "[Epoch: 26/30]  [Training Loss: 0.017]  [Test Loss: 0.003]  [Test Accuracy: 0.999]\n",
      "[Epoch: 27/30]  [Training Loss: 0.013]  [Test Loss: 0.002]  [Test Accuracy: 1.000]\n",
      "[Epoch: 28/30]  [Training Loss: 0.019]  [Test Loss: 0.005]  [Test Accuracy: 0.999]\n",
      "[Epoch: 29/30]  [Training Loss: 0.016]  [Test Loss: 0.027]  [Test Accuracy: 0.992]\n",
      "[Epoch: 30/30]  [Training Loss: 0.019]  [Test Loss: 0.003]  [Test Accuracy: 0.999]\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "steps = 0\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    net.train()\n",
    "    for images, labels in train_loader:   \n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()     \n",
    "        optimizer.zero_grad()\n",
    "        log_ps = net(images)\n",
    "        loss = loss_function(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        running_loss += loss.item()        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "                log_ps = net(images)\n",
    "                test_loss += loss_function(log_ps, labels)                \n",
    "                # ps = torch.exp(log_ps)\n",
    "                top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                equals = top_class.long() == labels.long().view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))                \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "        print(\"[Epoch: {}/{}] \".format(e+1, epochs),\n",
    "              \"[Training Loss: {:.3f}] \".format(running_loss/len(train_loader)),\n",
    "              \"[Test Loss: {:.3f}] \".format(test_loss/len(test_loader)),\n",
    "              \"[Test Accuracy: {:.3f}]\".format(accuracy/len(test_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
