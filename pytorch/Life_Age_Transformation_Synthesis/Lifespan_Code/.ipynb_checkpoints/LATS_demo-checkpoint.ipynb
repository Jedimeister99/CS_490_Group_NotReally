{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/royorel/Lifespan_Age_Transformation_Synthesis/blob/master/LATS_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jny9CGNw1Rjn"
   },
   "source": [
    "# Lifespan Age Transformation Synthesis Demo\n",
    "\n",
    "This Colab notebook demonstrates the capabilities of the GAN architecture proposed in our paper. \n",
    "\n",
    "This colab lets you try our method on your own image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhbnEdCV2kc-"
   },
   "source": [
    "First, let's download the github repository and install all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2uubo7PsvxQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Lifespan_Age_Transformation_Synthesis'...\n",
      "remote: Enumerating objects: 66, done.\u001b[K\n",
      "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
      "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
      "remote: Total 578 (delta 35), reused 19 (delta 9), pack-reused 512\u001b[K\n",
      "Receiving objects: 100% (578/578), 22.84 MiB | 41.81 MiB/s, done.\n",
      "Resolving deltas: 100% (354/354), done.\n",
      "Checking connectivity... done.\n",
      "/home/hortonbm/github/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/Lifespan_Age_Transformation_Synthesis\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/royorel/Lifespan_Age_Transformation_Synthesis\n",
    "%cd Lifespan_Age_Transformation_Synthesis/\n",
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKKNh_xl3AI2"
   },
   "source": [
    "Now let's download the pretrained models for males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ezAOkaHw4Q_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"download_models.py\", line 1, in <module>\r\n",
      "    import util.util as util\r\n",
      "  File \"/home/hortonbm/github/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/Lifespan_Age_Transformation_Synthesis/util/util.py\", line 9, in <module>\r\n",
      "    import torch\r\n",
      "ModuleNotFoundError: No module named 'torch'\r\n"
     ]
    }
   ],
   "source": [
    "!python download_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKl8INdX3IHv"
   },
   "source": [
    "Here, we import libraries and set options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQKoh2xrw697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "activation: lrelu\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "compare_to_trained_class: 1\n",
      "compare_to_trained_outputs: False\n",
      "conv_weight_norm: True\n",
      "dataroot: ./datasets/males/\n",
      "debug_mode: False\n",
      "decoder_norm: pixel\n",
      "deploy: False\n",
      "display_id: 1\n",
      "display_port: 8097\n",
      "display_single_pane_ncols: 6\n",
      "display_winsize: 256\n",
      "fineSize: 256\n",
      "full_progression: False\n",
      "gen_dim_per_style: 50\n",
      "gpu_ids: [0]\n",
      "how_many: 50\n",
      "id_enc_norm: pixel\n",
      "image_path_file: None\n",
      "in_the_wild: False\n",
      "input_nc: 3\n",
      "interp_step: 0.5\n",
      "isTrain: False\n",
      "loadSize: 256\n",
      "make_video: False\n",
      "max_dataset_size: inf\n",
      "nThreads: 4\n",
      "n_adaptive_blocks: 4\n",
      "n_downsample: 2\n",
      "name: debug\n",
      "ngf: 64\n",
      "no_cond_noise: False\n",
      "no_flip: False\n",
      "no_moving_avg: False\n",
      "normalize_mlp: True\n",
      "ntest: inf\n",
      "output_nc: 3\n",
      "phase: test\n",
      "random_seed: -1\n",
      "resize_or_crop: resize_and_crop\n",
      "results_dir: ./results/\n",
      "serial_batches: False\n",
      "sort_classes: True\n",
      "sort_order: ['0-2', '3-6', '7-9', '15-19', '30-39', '50-69']\n",
      "trained_class_jump: 1\n",
      "traverse: False\n",
      "use_modulated_conv: True\n",
      "use_resblk_pixel_norm: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--name NAME] [--gpu_ids GPU_IDS]\n",
      "                             [--checkpoints_dir CHECKPOINTS_DIR] [--batchSize BATCHSIZE]\n",
      "                             [--loadSize LOADSIZE] [--fineSize FINESIZE]\n",
      "                             [--input_nc INPUT_NC] [--output_nc OUTPUT_NC]\n",
      "                             [--dataroot DATAROOT] [--sort_classes SORT_CLASSES]\n",
      "                             [--sort_order SORT_ORDER] [--resize_or_crop RESIZE_OR_CROP]\n",
      "                             [--serial_batches] [--no_flip] [--nThreads NTHREADS]\n",
      "                             [--max_dataset_size MAX_DATASET_SIZE]\n",
      "                             [--display_single_pane_ncols DISPLAY_SINGLE_PANE_NCOLS]\n",
      "                             [--display_winsize DISPLAY_WINSIZE]\n",
      "                             [--display_port DISPLAY_PORT] [--display_id DISPLAY_ID]\n",
      "                             [--use_modulated_conv USE_MODULATED_CONV]\n",
      "                             [--conv_weight_norm CONV_WEIGHT_NORM]\n",
      "                             [--id_enc_norm ID_ENC_NORM] [--decoder_norm {pixel,none}]\n",
      "                             [--n_adaptive_blocks N_ADAPTIVE_BLOCKS]\n",
      "                             [--activation {relu,lrelu}] [--normalize_mlp NORMALIZE_MLP]\n",
      "                             [--no_moving_avg] [--use_resblk_pixel_norm] [--ngf NGF]\n",
      "                             [--no_cond_noise] [--gen_dim_per_style GEN_DIM_PER_STYLE]\n",
      "                             [--n_downsample N_DOWNSAMPLE] [--verbose]\n",
      "                             [--random_seed RANDOM_SEED] [--ntest NTEST]\n",
      "                             [--results_dir RESULTS_DIR] [--phase PHASE]\n",
      "                             [--which_epoch WHICH_EPOCH] [--how_many HOW_MANY]\n",
      "                             [--in_the_wild] [--traverse] [--full_progression]\n",
      "                             [--make_video] [--compare_to_trained_outputs]\n",
      "                             [--compare_to_trained_class COMPARE_TO_TRAINED_CLASS]\n",
      "                             [--trained_class_jump {1,2}] [--interp_step INTERP_STEP]\n",
      "                             [--deploy] [--image_path_file IMAGE_PATH_FILE]\n",
      "                             [--debug_mode]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/hortonbm/.local/share/jupyter/runtime/kernel-ae145f27-a6b0-4b13-864c-c4825f9422ef.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "from options.test_options import TestOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "opt = TestOptions().parse(save=False)\n",
    "opt.display_id = 0 # do not launch visdom\n",
    "opt.nThreads = 1   # test code only supports nThreads = 1\n",
    "opt.batchSize = 1  # test code only supports batchSize = 1\n",
    "opt.serial_batches = True  # no shuffle\n",
    "opt.no_flip = True  # no flip\n",
    "opt.in_the_wild = True # This triggers preprocessing of in the wild images in the dataloader\n",
    "opt.traverse = True # This tells the model to traverse the latent space between anchor classes\n",
    "opt.interp_step = 0.05 # this controls the number of images to interpolate between anchor classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TLOiDzgKtYyi"
   },
   "source": [
    "Don't worry about this message above, \n",
    "```\n",
    "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-c9d47a98-bdba-4a5f-9f0a-e1437c7228b6.json\n",
    "```\n",
    "everything is perfectly fine..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AFlzSi41Kzg"
   },
   "source": [
    "Next on, we call the data loader and the visualizer class that generates the video from the network outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxBYeTB18zkZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgingDataLoader\n",
      "dataset [MulticlassUnalignedDataset] was created\n"
     ]
    }
   ],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "visualizer = Visualizer(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AbUVdK74G5p"
   },
   "source": [
    "Here, we define our model.\n",
    "\n",
    "NOTE: if you plan to try the method for a female, change opt.name to 'females_model'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_0RChfq0YPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (id_encoder): IdentityEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): EqualConv2d(\n",
      "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (2): PixelNorm()\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (5): EqualConv2d(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (6): PixelNorm()\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (9): EqualConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (10): PixelNorm()\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (2): PixelNorm()\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (6): PixelNorm()\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (2): PixelNorm()\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (6): PixelNorm()\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (2): PixelNorm()\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (6): PixelNorm()\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (2): PixelNorm()\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): EqualConv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          )\n",
      "          (6): PixelNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (age_encoder): AgeEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): EqualConv2d(\n",
      "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (3): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (4): EqualConv2d(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (6): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (7): EqualConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (9): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (10): EqualConv2d(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (12): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (13): EqualConv2d(\n",
      "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (15): EqualConv2d(\n",
      "        (conv): Conv2d(1024, 300, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): StyledDecoder(\n",
      "    (StyledConvBlock_0): StyledConvBlock(\n",
      "      (conv0): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm0): PixelNorm()\n",
      "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (conv1): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm1): PixelNorm()\n",
      "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (StyledConvBlock_1): StyledConvBlock(\n",
      "      (conv0): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm0): PixelNorm()\n",
      "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (conv1): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm1): PixelNorm()\n",
      "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (StyledConvBlock_2): StyledConvBlock(\n",
      "      (conv0): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm0): PixelNorm()\n",
      "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (conv1): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm1): PixelNorm()\n",
      "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (StyledConvBlock_3): StyledConvBlock(\n",
      "      (conv0): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm0): PixelNorm()\n",
      "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (conv1): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm1): PixelNorm()\n",
      "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (StyledConvBlock_up0): StyledConvBlock(\n",
      "      (conv0): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      )\n",
      "      (pxl_norm0): PixelNorm()\n",
      "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (conv1): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=128, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm1): PixelNorm()\n",
      "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (StyledConvBlock_up1): StyledConvBlock(\n",
      "      (conv0): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=128, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      )\n",
      "      (pxl_norm0): PixelNorm()\n",
      "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (conv1): ModulatedConv2d(\n",
      "        (mlp_class_std): Sequential(\n",
      "          (0): EqualLinear(\n",
      "            (linear): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "          (1): PixelNorm()\n",
      "        )\n",
      "        (blur): Blur()\n",
      "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (pxl_norm1): PixelNorm()\n",
      "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (conv_img): Sequential(\n",
      "      (0): EqualConv2d(\n",
      "        (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (mlp): MLP(\n",
      "      (model): Sequential(\n",
      "        (0): PixelNorm()\n",
      "        (1): EqualLinear(\n",
      "          (linear): Linear(in_features=300, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (3): PixelNorm()\n",
      "        (4): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (6): PixelNorm()\n",
      "        (7): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (9): PixelNorm()\n",
      "        (10): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (12): PixelNorm()\n",
      "        (13): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (15): PixelNorm()\n",
      "        (16): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (17): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (18): PixelNorm()\n",
      "        (19): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (20): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (21): PixelNorm()\n",
      "        (22): EqualLinear(\n",
      "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (23): PixelNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InferenceModel(\n",
       "  (netG): Generator(\n",
       "    (id_encoder): IdentityEncoder(\n",
       "      (encoder): Sequential(\n",
       "        (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "        (1): EqualConv2d(\n",
       "          (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "        )\n",
       "        (2): PixelNorm()\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): EqualConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "        (6): PixelNorm()\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (9): EqualConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "        (10): PixelNorm()\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): ResnetBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (2): PixelNorm()\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (5): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (6): PixelNorm()\n",
       "          )\n",
       "        )\n",
       "        (13): ResnetBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (2): PixelNorm()\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (5): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (6): PixelNorm()\n",
       "          )\n",
       "        )\n",
       "        (14): ResnetBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (2): PixelNorm()\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (5): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (6): PixelNorm()\n",
       "          )\n",
       "        )\n",
       "        (15): ResnetBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (2): PixelNorm()\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (5): EqualConv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (6): PixelNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (age_encoder): AgeEncoder(\n",
       "      (encoder): Sequential(\n",
       "        (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "        (1): EqualConv2d(\n",
       "          (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "        )\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (4): EqualConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (6): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (7): EqualConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "        (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (9): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (10): EqualConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "        (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (12): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (13): EqualConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "        (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (15): EqualConv2d(\n",
       "          (conv): Conv2d(1024, 300, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): StyledDecoder(\n",
       "      (StyledConvBlock_0): StyledConvBlock(\n",
       "        (conv0): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm0): PixelNorm()\n",
       "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm1): PixelNorm()\n",
       "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (StyledConvBlock_1): StyledConvBlock(\n",
       "        (conv0): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm0): PixelNorm()\n",
       "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm1): PixelNorm()\n",
       "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (StyledConvBlock_2): StyledConvBlock(\n",
       "        (conv0): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm0): PixelNorm()\n",
       "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm1): PixelNorm()\n",
       "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (StyledConvBlock_3): StyledConvBlock(\n",
       "        (conv0): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm0): PixelNorm()\n",
       "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm1): PixelNorm()\n",
       "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (StyledConvBlock_up0): StyledConvBlock(\n",
       "        (conv0): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        )\n",
       "        (pxl_norm0): PixelNorm()\n",
       "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm1): PixelNorm()\n",
       "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (StyledConvBlock_up1): StyledConvBlock(\n",
       "        (conv0): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        )\n",
       "        (pxl_norm0): PixelNorm()\n",
       "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): ModulatedConv2d(\n",
       "          (mlp_class_std): Sequential(\n",
       "            (0): EqualLinear(\n",
       "              (linear): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (1): PixelNorm()\n",
       "          )\n",
       "          (blur): Blur()\n",
       "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (pxl_norm1): PixelNorm()\n",
       "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (conv_img): Sequential(\n",
       "        (0): EqualConv2d(\n",
       "          (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Tanh()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (model): Sequential(\n",
       "          (0): PixelNorm()\n",
       "          (1): EqualLinear(\n",
       "            (linear): Linear(in_features=300, out_features=256, bias=True)\n",
       "          )\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): PixelNorm()\n",
       "          (4): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (6): PixelNorm()\n",
       "          (7): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (9): PixelNorm()\n",
       "          (10): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (12): PixelNorm()\n",
       "          (13): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (15): PixelNorm()\n",
       "          (16): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (17): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (18): PixelNorm()\n",
       "          (19): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (20): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (21): PixelNorm()\n",
       "          (22): EqualLinear(\n",
       "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (23): PixelNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.name = 'males_model' # change to 'females model' if you're trying the code on a female image\n",
    "model = create_model(opt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APhLIBEg4gnk"
   },
   "source": [
    "OK, it's time to upload your image.\n",
    "\n",
    "For best results, use images according to the following guidelines:\n",
    "\n",
    "1. The image should contain a single face.\n",
    "2. Image was taken from a digital camera (phone cameras are fine). Old images from film cameras would produce low quality results.\n",
    "3. Pure RGB images only. No black & white, grayscale, sepia, or filtered images (e.g. Instagram filters).\n",
    "4. Person's head should directly face the camera. Looking sideways/downwards/upwards degrades the results.\n",
    "5. The person's face should not be occluded (or partially occluded) by any item.\n",
    "6. Both eyes should be open and visible. (eyeglasses are ok, no sunglasses)\n",
    "\n",
    "Your uploaded images are local to the Colab instance and are not accessible by the paper authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSUbmd697Api"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User uploaded file \"/media/Data/CK+/CK+/cohn-kanade-images/S005/001/S005_001_00000001.png\"\n"
     ]
    }
   ],
   "source": [
    "# upload your image (the code supports only a signle image at a time)\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#for filename in uploaded.keys():\n",
    "filename = '/media/Data/CK+/CK+/cohn-kanade-images/S005/001/S005_001_00000001.png'\n",
    "img_path = filename\n",
    "print('User uploaded file \"{name}\"'.format(name=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgxXQ4tu45V5"
   },
   "source": [
    "Finally, we preprocess the image, run the network, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJ3Az0VY3Fwt"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.21 GiB (GPU 0; 7.92 GiB total capacity; 4.47 GiB already allocated; 1.45 GiB free; 5.79 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-faacc379973f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_item_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/models/LATS_model.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_conditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_conditions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/models/networks.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, input, target_age_features, traverse, deploy, interp_step)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mid_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/models/networks.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, id_features, target_age_features, traverse, deploy, interp_step)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SCIENCE/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, id_features, target_age, traverse, deploy, interp_step)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyledConvBlock_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyledConvBlock_up0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyledConvBlock_up1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SCIENCE/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, latent)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodulated_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SCIENCE/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS_490_Group_NotReally/pytorch/Life_Age_Transformation_Synthesis/Lifespan_Code/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, latent)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SCIENCE/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SCIENCE/lib/python3.8/site-packages/torch/nn/modules/padding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SCIENCE/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   3567\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4D tensors expect 4 values for padding'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflection_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplication_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.21 GiB (GPU 0; 7.92 GiB total capacity; 4.47 GiB already allocated; 1.45 GiB free; 5.79 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "data = dataset.dataset.get_item_from_path(img_path)\n",
    "visuals = model.inference(data)\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "out_path = os.path.join('results', os.path.splitext(img_path)[0] + '.mp4')\n",
    "visualizer.make_video(visuals, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRCyM2i65ZdB"
   },
   "source": [
    "Let's display at the results.\n",
    "\n",
    "NOTE: if you're using chrome, uncomment the lines below. For some reason, mp4 files won't display on chrome browser, so we need to convert to webm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwjp6STO3hCz"
   },
   "outputs": [],
   "source": [
    "use_webm = False\n",
    "# For some unknown reason the mp4 video is not displayed on chrome\n",
    "# If you have chrome, uncomment the following lines to convert the \n",
    "# result to webm for display purposes\n",
    "\n",
    "# !pip3 install webm\n",
    "# webm_out_path = os.path.join('results', os.path.splitext(img_path)[0] + '.webm')\n",
    "# !webm -i $out_path $webm_out_path\n",
    "# use_webm = True\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "video_path = webm_out_path if use_webm else out_path\n",
    "video_type = \"video/webm\" if use_webm else \"video/mp4\"\n",
    "mp4 = open(video_path,'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width={0} controls>\n",
    "      <source src=\"{1}\" type=\"{2}\">\n",
    "</video>\n",
    "\"\"\".format(opt.fineSize, data_url, video_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-RLnTezc59FZ"
   },
   "source": [
    "You can download the result if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0W87da7s9FM1"
   },
   "outputs": [],
   "source": [
    "files.download(out_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPQDFCGCLebkS43l9I5Zr1T",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LATS_demo.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
